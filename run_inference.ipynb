{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70951ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "\n",
    "import pathlib\n",
    "import config as cfg\n",
    "\n",
    "from tokenizer.tokenizer import ByteLevelBPE, TokenizerHF\n",
    "\n",
    "import importlib\n",
    "\n",
    "from model.CPTR_upd import CPTR\n",
    "\n",
    "from model.helpers import *\n",
    "\n",
    "from dataset.loader import DatasetLoader\n",
    "\n",
    "import copy\n",
    "\n",
    "from save_results import save_results_smart, list_saved_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040ca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(cfg)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbcbf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = cfg.CONFIG_ROOT / \"results/config_20260121-012640\"\n",
    "config = cfg.import_config(model_folder / 'config.json')\n",
    "model_path = model_folder / 'cptr_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = config[\"BATCH_SIZE_TRAIN\"]\n",
    "batch_size_test = config[\"BATCH_SIZE_TEST\"]\n",
    "\n",
    "H = config[\"IMG_HEIGHT\"]\n",
    "W = config[\"IMG_WIDTH\"]\n",
    "P = config[\"PATCH_SIZE\"]\n",
    "D_IMG = config[\"IMG_EMBEDDING_DIM\"]\n",
    "\n",
    "# The data will get truncated/padded to this length AFTER tokenization\n",
    "L = config[\"MAX_TEXT_SEQUENCE_LENGTH\"]\n",
    "D_TEXT = config[\"TEXT_EMBEDDING_DIM\"]\n",
    "DROPOUT_DEC = config[\"DECODER_DROPOUT_PROB\"]\n",
    "RANDOM_SEED = config[\"RANDOM_SEED\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab6eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DatasetLoader(dataset_type=config[\"DATASET\"],\n",
    "                            img_height=H,\n",
    "                            img_width=W,\n",
    "                            batch_size_train=batch_size_train, \n",
    "                            batch_size_test=batch_size_test,\n",
    "                            split_ratio=config[\"SPLIT_RATIO\"],\n",
    "                            shuffle_test=True,\n",
    "                            seed=RANDOM_SEED)\n",
    "data_loader.load_data()\n",
    "\n",
    "train_dataloader = data_loader.get_train_dataloader()\n",
    "test_dataloader = data_loader.get_test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1511bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [cfg.SpecialTokens.PAD, cfg.SpecialTokens.BOS, cfg.SpecialTokens.EOS]\n",
    "if config[\"TOKENIZER_TYPE\"] == cfg.TokenizerType.HF:\n",
    "    tokenizer = TokenizerHF()\n",
    "elif config[\"TOKENIZER_TYPE\"] == cfg.TokenizerType.BPE:\n",
    "    tokenizer = ByteLevelBPE(special_tokens=special_tokens)\n",
    "    tokenizer.load(folder=config[\"TOKENIZER_DATA_PATH\"], filename_prefix=config[\"TOKENIZER_FILENAME_PREFIX\"])\n",
    "    \n",
    "pad_idx = tokenizer.get_padding_token_id()\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "print(f\"Tokenizer vocab size: {vocab_size}, Pad token ID: {pad_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = CPTR(num_patches=config[\"NUM_PATCHES\"],\n",
    "                   encoder_arch=config[\"ENCODER_ARCH\"],\n",
    "                   encoding_strategy=config[\"VIT_ENCODING_STRATEGY\"],\n",
    "                   use_embedding_projection=config[\"USE_PROJECTION_LAYER\"],\n",
    "                   img_emb_use_conv=config[\"USE_CONV_IMG_EMBEDDING\"],\n",
    "                   img_emb_dim=config[\"IMG_EMBEDDING_DIM\"],\n",
    "                   patch_size=config[\"PATCH_SIZE\"],\n",
    "                   text_emb_dim=config[\"TEXT_EMBEDDING_DIM\"],\n",
    "                   d_model=config[\"EMBEDDING_DIM\"],\n",
    "                   max_text_seq_len=config[\"MAX_TEXT_SEQUENCE_LENGTH\"],\n",
    "                   vocab_size=vocab_size,\n",
    "                   pad_idx=pad_idx,\n",
    "                   channels=config[\"NUM_INPUT_CHANNELS\"],\n",
    "                   num_encoder_blocks=config[\"ENCODER_NUM_BLOCKS\"],\n",
    "                   num_encoder_heads=config[\"ENCODER_NUM_HEADS\"],\n",
    "                   encoder_hidden_dim=config[\"ENCODER_HIDDEN_DIM\"],\n",
    "                   encoder_dropout_prob=config[\"ENCODER_DROPOUT_PROB\"],\n",
    "                   num_decoder_blocks=config[\"DECODER_NUM_BLOCKS\"],\n",
    "                   num_decoder_heads=config[\"DECODER_NUM_HEADS\"],\n",
    "                   decoder_hidden_dim=config[\"DECODER_HIDDEN_DIM\"],\n",
    "                   decoder_dropout_prob=config[\"DECODER_DROPOUT_PROB\"],\n",
    "                   bias=config[\"USE_BIAS\"],\n",
    "                   use_weight_tying=config[\"USE_WEIGHT_TYING\"],\n",
    "                   sublayer_dropout=config[\"SUBLAYER_DROPOUT\"],\n",
    "                   verbose=False).to(device)\n",
    "transformer.load_state_dict(torch.load(model_path, map_location=device))\n",
    "transformer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d0939",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "image = batch[\"pixel_values\"][0].unsqueeze(0).to(device)\n",
    "print('Caption GT: ', batch[\"description\"][0])\n",
    "print('Input image shape:', image.shape)\n",
    "# plot input image\n",
    "img = image[0].cpu().permute(1, 2, 0).numpy()\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "tokens = transformer.generate(image, \n",
    "        bos_token=tokenizer.get_vocab()[cfg.SpecialTokens.BOS.value],\n",
    "        eos_token=tokenizer.get_vocab()[cfg.SpecialTokens.EOS.value],\n",
    "        max_len=L,\n",
    "        device=device)\n",
    "if not isinstance(tokens, torch.Tensor):\n",
    "        tokens = torch.tensor(tokens)\n",
    "print('Generated token ids:', tokens)\n",
    "print(tokens.shape)\n",
    "decoded_caption = tokenizer.decode(tokens)\n",
    "print('Generated caption:', decoded_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4519318",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_dataloader))\n",
    "image = batch[\"pixel_values\"][0].unsqueeze(0).to(device)\n",
    "print('Caption GT: ', batch[\"description\"][0])\n",
    "print('Input image shape:', image.shape)\n",
    "# plot input image\n",
    "img = image[0].cpu().permute(1, 2, 0).numpy()\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "tokens = transformer.generate(image, \n",
    "        bos_token=tokenizer.get_vocab()[cfg.SpecialTokens.BOS.value],\n",
    "        eos_token=tokenizer.get_vocab()[cfg.SpecialTokens.EOS.value],\n",
    "        max_len=L,\n",
    "        device=device)\n",
    "if not isinstance(tokens, torch.Tensor):\n",
    "        tokens = torch.tensor(tokens)\n",
    "print('Generated token ids:', tokens)\n",
    "print(tokens.shape)\n",
    "decoded_caption = tokenizer.decode(tokens)\n",
    "print('Generated caption:', decoded_caption)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
