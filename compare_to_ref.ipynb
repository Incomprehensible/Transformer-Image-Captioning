{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd9aca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nad/studies/Transformer-Image-Captioning-IIW/.env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import config\n",
    "\n",
    "from tokenizer import ByteLevelBPE\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c463998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attn_mask: If specified, a 2D or 3D mask preventing attention to certain positions. Must be of shape\n",
    "#                 :math:`(L, S)` or :math:`(N\\cdot\\text{num\\_heads}, L, S)`, where :math:`N` is the batch size,\n",
    "#                 :math:`L` is the target sequence length, and :math:`S` is the source sequence length. A 2D mask will be\n",
    "#                 broadcasted across the batch while a 3D mask allows for a different mask for each entry in the batch.\n",
    "#                 Binary and float masks are supported. For a binary mask, a ``True`` value indicates that the\n",
    "#                 corresponding position is not allowed to attend. For a float mask, the mask values will be added to\n",
    "#                 the attention weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d286c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPTR paper\n",
    "def create_mask(seq_length, verbose=False):\n",
    "    mask = torch.tril(torch.ones((seq_length, seq_length)))  #(1)\n",
    "    mask[mask == 0] = -float('inf')  #(2)\n",
    "    mask[mask == 1] = 0  #(3)\n",
    "    if verbose:\n",
    "        print('Reference causal mask shape:', mask.shape)\n",
    "        plt.imshow(mask.cpu(), cmap='gray', aspect='auto')\n",
    "        plt.title('Reference Causal Mask (White = Blocked, Black = Allowed)')\n",
    "        plt.xlabel('Sequence Length')\n",
    "        plt.ylabel('Sequence Length')\n",
    "        plt.show()\n",
    "    return mask\n",
    "\n",
    "# mine\n",
    "\n",
    "# size: (seq_len, seq_len)\n",
    "def get_causal_mask(seq_len, device='cpu', verbose=False):\n",
    "    attn_mask = torch.triu(torch.ones((seq_len, seq_len), device=device, requires_grad=False), diagonal=1).bool()  # Upper triangular matrix\n",
    "    if verbose:\n",
    "        print('Causal mask shape:', attn_mask.shape)\n",
    "        # visualize the mask in matplotlib\n",
    "        plt.imshow(attn_mask.cpu(), cmap='gray', aspect='auto')\n",
    "        plt.title('Causal Mask (White = Blocked, Black = Allowed)')\n",
    "        plt.xlabel('Sequence Length')\n",
    "        plt.ylabel('Sequence Length')\n",
    "        plt.show()\n",
    "    return attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc4670a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal mask shape: torch.Size([10, 10])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False]])\n",
      "torch.bool\n",
      "Reference causal mask shape: torch.Size([10, 10])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10\n",
    "\n",
    "attn_mask = get_causal_mask(seq_len, device='cpu', verbose=True)\n",
    "print(attn_mask)  # Print the mask tensor\n",
    "print(attn_mask.dtype)\n",
    "\n",
    "# CPTR paper\n",
    "attn_mask = create_mask(seq_length=seq_len, verbose=True)\n",
    "print(attn_mask)  # Print the mask tensor\n",
    "print(attn_mask.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8531a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_padding_mask: If specified, a mask of shape :math:`(N, S)` indicating which elements within ``key``\n",
    "#                 to ignore for the purpose of attention (i.e. treat as \"padding\"). For unbatched `query`, shape should be :math:`(S)`.\n",
    "#                 Binary and float masks are supported.\n",
    "#                 For a binary mask, a ``True`` value indicates that the corresponding ``key`` value will be ignored for\n",
    "#                 the purpose of attention. For a float mask, it will be directly added to the corresponding ``key`` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da46ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                 If both attn_mask and key_padding_mask are supplied, their types should match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6703c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: (batch_size, seq_len)\n",
    "def get_padding_mask(decoder_inputs, pad_idx, device='cpu', verbose=False):\n",
    "    pad_mask = torch.zeros(decoder_inputs.size(0), decoder_inputs.size(1), dtype=torch.bool, device=device, requires_grad=False)\n",
    "    pad_mask[(decoder_inputs == pad_idx)] = True\n",
    "    if verbose:\n",
    "        print('Padding mask shape:', pad_mask.shape)\n",
    "        # visualize the mask in matplotlib\n",
    "        plt.imshow(pad_mask.cpu(), cmap='gray', aspect='auto')\n",
    "        plt.title('Padding Mask (White = Blocked, Black = Allowed)')\n",
    "        plt.xlabel('Sequence Length')\n",
    "        plt.ylabel('Batch Size')\n",
    "        plt.show()\n",
    "    return pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6928861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding mask shape: torch.Size([2, 10])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [False, False,  True,  True,  True,  True,  True,  True,  True,  True]])\n",
      "torch.bool\n"
     ]
    }
   ],
   "source": [
    "mask = get_padding_mask(torch.tensor([[1,2,3,0,0,0,0,0,0,0],[4,5,0,0,0,0,0,0,0,0]]), pad_idx=0, device='cpu', verbose=True)\n",
    "print(mask)  # Print the mask tensor\n",
    "print(mask.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "411aa86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPTR paper\n",
    "class Patcher_(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #(1)\n",
    "        self.unfold = torch.nn.Unfold(kernel_size=config.PATCH_SIZE, stride=config.PATCH_SIZE)\n",
    "\n",
    "        #(2)\n",
    "        self.linear_projection = torch.nn.Linear(in_features=config.NUM_INPUT_CHANNELS*config.PATCH_SIZE*config.PATCH_SIZE, \n",
    "                                           out_features=config.EMBEDDING_DIM)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        print(f'images\\t\\t: {images.size()}')\n",
    "        \n",
    "        images = self.unfold(images)  #(3)\n",
    "        print(f'after unfold\\t: {images.size()}')\n",
    "        \n",
    "        images = images.permute(0, 2, 1)  #(4)\n",
    "        print(f'after permute\\t: {images.size()}')\n",
    "        \n",
    "        features = self.linear_projection(images)  #(5)\n",
    "        print(f'after lin proj\\t: {features.size()}')\n",
    "        \n",
    "        return features\n",
    "\n",
    "# mine\n",
    "class Patcher(torch.nn.Module):\n",
    "    def __init__(self, patch_size=config.PATCH_SIZE, channels=config.NUM_INPUT_CHANNELS, emb_dim=config.IMG_EMBEDDING_DIM, bias=config.USE_BIAS):\n",
    "        super(Patcher, self).__init__()\n",
    "        self.P = patch_size\n",
    "        self.C = channels\n",
    "        self.D = emb_dim\n",
    "        \n",
    "        self.patcher = torch.nn.Unfold(kernel_size=self.P, stride=self.P)\n",
    "        self.linear_embedding = torch.nn.Linear(in_features=self.P*self.P*self.C, out_features=self.D, bias=bias)\n",
    "    \n",
    "    def forward(self, images):\n",
    "        print(f'Input images shape: {images.shape}')\n",
    "        if images.ndim < 4:\n",
    "            images = images.unsqueeze(0)\n",
    "        \n",
    "        print(f'After unfold: ', self.patcher(images).shape)\n",
    "        patches = self.patcher(images).permute(0, 2, 1)  # shape: (batch, num_patches, P*P*C)\n",
    "        print(f'After permute: {patches.shape}')\n",
    "        patches = self.linear_embedding(patches)  # shape: (batch, num_patches, D)\n",
    "        print(f'After linear proj: {patches.shape}')\n",
    "        return patches\n",
    "    \n",
    "    def get_linear_weights(self):\n",
    "        return self.linear_embedding.weight\n",
    "    \n",
    "\n",
    "class ConvPatcher(torch.nn.Module):\n",
    "    def __init__(self, patch_size=config.PATCH_SIZE, channels=config.NUM_INPUT_CHANNELS, emb_dim=config.IMG_EMBEDDING_DIM, bias=config.USE_BIAS, visualize_patches=False):\n",
    "        super(ConvPatcher, self).__init__()\n",
    "        self.P = patch_size\n",
    "        self.C = channels\n",
    "        self.D = emb_dim\n",
    "        self.visualize = visualize_patches\n",
    "\n",
    "        self.conv = torch.nn.Conv2d(in_channels=self.C, out_channels=self.D, kernel_size=self.P, stride=self.P, bias=bias, padding=0)\n",
    "\n",
    "    def visualize_patches(self, convs, num=5):\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=5, figsize=(12, 12))\n",
    "        \n",
    "        # Plot random image feature maps\n",
    "        random_indexes = random.sample(range(0, self.D), k=num) # pick 5 numbers between 0 and the embedding size\n",
    "        for i, idx in enumerate(random_indexes):\n",
    "            image_conv_feature_map = convs[0, idx, :, :].squeeze().detach().cpu().numpy() # index on the output tensor of the convolutional layer\n",
    "            axs[i].imshow(image_conv_feature_map, cmap='twilight')\n",
    "            axs[i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "        plt.show()\n",
    "    \n",
    "    def forward(self, images):\n",
    "        if images.ndim < 4:\n",
    "            images = images.unsqueeze(0)\n",
    "        \n",
    "        # embedding dimension D becomes the number of output feature maps\n",
    "        patches = self.conv(images)  # shape: (batch_size, embedding_dim, feature_map_height, feature_map_width)\n",
    "        if self.visualize:\n",
    "            self.visualize_patches(patches, num=5)\n",
    "        patches = patches.reshape(patches.shape[0], patches.shape[1], -1)  # shape: (batch_size, embedding_dim, num_patches)\n",
    "        patches = patches.permute(0, 2, 1)\n",
    "        print(f'After conv proj: {patches.shape}')\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa7ae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\t\t: torch.Size([16, 3, 224, 224])\n",
      "after unfold\t: torch.Size([16, 768, 196])\n",
      "after permute\t: torch.Size([16, 196, 768])\n",
      "after lin proj\t: torch.Size([16, 196, 768])\n",
      "Input images shape: torch.Size([16, 3, 224, 224])\n",
      "After unfold:  torch.Size([16, 768, 196])\n",
      "After permute: torch.Size([16, 196, 768])\n",
      "After linear proj: torch.Size([16, 196, 768])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After conv proj: torch.Size([16, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "patcher  = Patcher_()\n",
    "\n",
    "images   = torch.randn(config.BATCH_SIZE_TRAIN, config.NUM_INPUT_CHANNELS, config.IMG_HEIGHT, config.IMG_WIDTH)\n",
    "features = patcher(images)\n",
    "\n",
    "patcher = Patcher()\n",
    "features = patcher(images)\n",
    "\n",
    "patcher = ConvPatcher(visualize_patches=True)\n",
    "features = patcher(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0487216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPTR paper\n",
    "class LearnableEmbedding(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.learnable_embedding = torch.nn.Parameter(torch.randn(size=(config.NUM_PATCHES, config.EMBEDDING_DIM)), \n",
    "                                                requires_grad=True)\n",
    "        \n",
    "    def forward(self):\n",
    "        pos_embed = self.learnable_embedding\n",
    "        print(f'learnable embedding\\t: {pos_embed.size()}')\n",
    "        \n",
    "        return pos_embed\n",
    "\n",
    "\n",
    "class LearnablePositionalEmbedding(torch.nn.Module):\n",
    "    def __init__(self, num_patches=config.NUM_PATCHES, emb_dim=config.IMG_EMBEDDING_DIM):\n",
    "        super(LearnablePositionalEmbedding, self).__init__()\n",
    "        self.pos_embedding = torch.nn.Parameter(requires_grad=True, data=torch.randn(size=(1, num_patches, emb_dim)))\n",
    "\n",
    "    def forward(self):\n",
    "        print(f'learnable embedding\\t: {self.pos_embedding.size()}')\n",
    "        return self.pos_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ce33acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learnable embedding\t: torch.Size([196, 768])\n",
      "learnable embedding\t: torch.Size([1, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "emb = LearnableEmbedding()\n",
    "pos_embed = emb()\n",
    "\n",
    "emb = LearnablePositionalEmbedding()\n",
    "pos_embed = emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701073c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPTR paper\n",
    "class EncoderBlock(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.self_attention = torch.nn.MultiheadAttention(embed_dim=config.IMG_EMBEDDING_DIM,\n",
    "                                                    num_heads=config.ENCODER_NUM_HEADS, \n",
    "                                                    batch_first=True,  #(2)\n",
    "                                                    dropout=config.ENCODER_DROPOUT_PROB)\n",
    "        \n",
    "        self.layer_norm_0 = torch.nn.LayerNorm(config.IMG_EMBEDDING_DIM)  #(3)\n",
    "        self.ffn = torch.nn.Sequential(  #(4)\n",
    "            torch.nn.Linear(in_features=config.IMG_EMBEDDING_DIM, out_features=config.ENCODER_HIDDEN_DIM),\n",
    "            torch.nn.GELU(), \n",
    "            torch.nn.Dropout(p=config.ENCODER_DROPOUT_PROB), \n",
    "            torch.nn.Linear(in_features=config.ENCODER_HIDDEN_DIM, out_features=config.IMG_EMBEDDING_DIM),\n",
    "        )\n",
    "        self.layer_norm_1 = torch.nn.LayerNorm(config.IMG_EMBEDDING_DIM)  #(5)\n",
    "        \n",
    "# Codeblock 7b\n",
    "    def forward(self, features):  #(1)\n",
    "        residual = features  #(2)\n",
    "        print(f'features & residual\\t: {residual.size()}')\n",
    "        \n",
    "        features, self_attn_weights = self.self_attention(query=features, \n",
    "                                                          key=features, \n",
    "                                                          value=features)\n",
    "        print(f'after self attention\\t: {features.size()}')\n",
    "        print(f\"self attn weights\\t: {self_attn_weights.shape}\")\n",
    "        \n",
    "        features = self.layer_norm_0(features + residual)  #(4)\n",
    "        print(f'after norm\\t\\t: {features.size()}')\n",
    "        \n",
    "        residual = features\n",
    "        print(f'\\nfeatures & residual\\t: {residual.size()}')\n",
    "        \n",
    "        features = self.ffn(features)  #(5)\n",
    "        print(f'after ffn\\t\\t: {features.size()}')\n",
    "        \n",
    "        features = self.layer_norm_1(features + residual)\n",
    "        print(f'after norm\\t\\t: {features.size()}')\n",
    "        \n",
    "        return features\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.patcher = Patcher()  #(1)\n",
    "        self.learnable_embedding = LearnableEmbedding()  #(2)\n",
    "\n",
    "        self.encoder_blocks = torch.nn.ModuleList(EncoderBlock() for _ in range(config.ENCODER_NUM_BLOCKS))\n",
    "    \n",
    "    def forward(self, images):  #(4)\n",
    "        print(f'images\\t\\t\\t: {images.size()}')\n",
    "        \n",
    "        features = self.patcher(images)  #(5)\n",
    "        print(f'after patcher\\t\\t: {features.size()}')\n",
    "        \n",
    "        features = features + self.learnable_embedding()  #(6)\n",
    "        print(f'after learn embed\\t: {features.size()}')\n",
    "        \n",
    "        for i, encoder_block in enumerate(self.encoder_blocks):\n",
    "            features = encoder_block(features)  #(7)\n",
    "            print(f\"after encoder block #{i}\\t: {features.shape}\")\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0ba1da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\t\t\t: torch.Size([16, 3, 224, 224])\n",
      "Input images shape: torch.Size([16, 3, 224, 224])\n",
      "After unfold:  torch.Size([16, 768, 196])\n",
      "After permute: torch.Size([16, 196, 768])\n",
      "After linear proj: torch.Size([16, 196, 768])\n",
      "after patcher\t\t: torch.Size([16, 196, 768])\n",
      "learnable embedding\t: torch.Size([196, 768])\n",
      "after learn embed\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block #0\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block #1\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block #2\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block #3\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block #4\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block #5\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block #6\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block #7\t: torch.Size([16, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder()\n",
    "images  = torch.randn(config.BATCH_SIZE_TRAIN, config.NUM_INPUT_CHANNELS, config.IMG_HEIGHT, config.IMG_WIDTH)\n",
    "output = encoder(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70ef5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine\n",
    "class EncoderBlock(torch.nn.Module):\n",
    "    def __init__(self, embed_dim=config.IMG_EMBEDDING_DIM, num_heads=config.ENCODER_NUM_HEADS, hidden_dim=config.ENCODER_HIDDEN_DIM, dropout_prob=config.ENCODER_DROPOUT_PROB, bias=config.USE_BIAS, sublayer_dropout=config.SUBLAYER_DROPOUT):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.MHSA = torch.nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, batch_first=True, dropout=dropout_prob, bias=bias)\n",
    "        self.layer_norm_1 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.FFN = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embed_dim, hidden_dim, bias=bias),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(p=dropout_prob),\n",
    "            torch.nn.Linear(hidden_dim, embed_dim, bias=bias)\n",
    "        )\n",
    "        self.layer_norm_2 = torch.nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        if sublayer_dropout:\n",
    "            self.sublayer_dropout = torch.nn.Dropout(p=dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        print(f'features & residual\\t: {x.size()}')\n",
    "        \n",
    "        attn_output, weights = self.MHSA(query=x, key=x, value=x)\n",
    "        \n",
    "        print(f'after self attention\\t: {attn_output.size()}')\n",
    "        print(f\"self attn weights\\t: {weights.shape}\")\n",
    "        \n",
    "        if hasattr(self, 'sublayer_dropout'):\n",
    "            attn_output = self.sublayer_dropout(attn_output)\n",
    "            print(f'after sublayer dropout\\t: {attn_output.size()}')\n",
    "        \n",
    "        assert residual is x  # just to use residual variable and avoid linter warning\n",
    "        x = self.layer_norm_1(x + attn_output)\n",
    "        print(f'after norm\\t\\t: {x.size()}')\n",
    "        \n",
    "        residual = x\n",
    "        print(f'\\nfeatures & residual\\t: {x.size()}')\n",
    "\n",
    "        ff_output = self.FFN(x)\n",
    "        print(f'after ffn\\t\\t: {ff_output.size()}')\n",
    "        \n",
    "        assert residual is x  # just to use residual variable and avoid linter warning\n",
    "        x = self.layer_norm_2(x + ff_output)\n",
    "        print(f'after norm\\t\\t: {x.size()}')\n",
    "        \n",
    "        return x\n",
    "\n",
    "# takes patches after linear projection and positional encoding\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, num_blocks=config.ENCODER_NUM_BLOCKS, embed_dim=config.IMG_EMBEDDING_DIM, num_heads=config.ENCODER_NUM_HEADS, hidden_dim=config.ENCODER_HIDDEN_DIM, dropout_prob=config.ENCODER_DROPOUT_PROB, bias=config.USE_BIAS, sublayer_dropout=config.SUBLAYER_DROPOUT):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder_blocks = torch.nn.ModuleList()\n",
    "        for _ in range(num_blocks):\n",
    "            self.encoder_blocks.append(EncoderBlock(embed_dim=embed_dim, num_heads=num_heads, hidden_dim=hidden_dim, dropout_prob=dropout_prob, bias=bias, sublayer_dropout=sublayer_dropout))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x)\n",
    "            print(f'after encoder block\\t: {x.size()}')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aeb1949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After conv proj: torch.Size([16, 196, 768])\n",
      "after patcher\t\t: torch.Size([16, 196, 768])\n",
      "learnable embedding\t: torch.Size([1, 196, 768])\n",
      "after learnable emb\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block\t: torch.Size([16, 196, 768])\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after self attention\t: torch.Size([16, 196, 768])\n",
      "self attn weights\t: torch.Size([16, 196, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "\n",
      "features & residual\t: torch.Size([16, 196, 768])\n",
      "after ffn\t\t: torch.Size([16, 196, 768])\n",
      "after norm\t\t: torch.Size([16, 196, 768])\n",
      "after encoder block\t: torch.Size([16, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "patcher = ConvPatcher()\n",
    "img_pos_embedding = LearnablePositionalEmbedding()\n",
    "encoder = Encoder()\n",
    "patches = patcher(images)\n",
    "print(f'after patcher\\t\\t: {patches.size()}')\n",
    "pos_emb = img_pos_embedding()\n",
    "emb = patches + pos_emb\n",
    "print(f'after learnable emb\\t: {emb.size()}')\n",
    "output2 = encoder(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "559d4df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Output 1 - mean: 6.335527588663403e-12, std: 0.9999954104423523\n",
      "Encoder Output 2 - mean: 5.606942132807546e-10, std: 0.9999954104423523\n"
     ]
    }
   ],
   "source": [
    "# compare encoders outputs by computing mean and std\n",
    "mean_output = output.mean().item()\n",
    "std_output = output.std().item()\n",
    "mean_output2 = output2.mean().item()\n",
    "std_output2 = output2.std().item()\n",
    "print(f\"Encoder Output 1 - mean: {mean_output}, std: {std_output}\")\n",
    "print(f\"Encoder Output 2 - mean: {mean_output2}, std: {std_output2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63c48323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPTR paper\n",
    "class SinusoidalEmbedding(torch.nn.Module):\n",
    "    def forward(self, seq_len=config.MAX_TEXT_SEQUENCE_LENGTH):\n",
    "        pos = torch.arange(seq_len).reshape(seq_len, 1)\n",
    "        #print(f\"pos\\t\\t: {pos.shape}\")\n",
    "        \n",
    "        i = torch.arange(0, config.EMBEDDING_DIM, 2)\n",
    "        denominator = torch.pow(10000, i/config.EMBEDDING_DIM)\n",
    "        #print(f\"denominator\\t: {denominator.shape}\")\n",
    "        \n",
    "        even_pos_embed = torch.sin(pos/denominator)  #(1)\n",
    "        odd_pos_embed  = torch.cos(pos/denominator)  #(2)\n",
    "        #print(f\"even_pos_embed\\t: {even_pos_embed.shape}\")\n",
    "        \n",
    "        stacked = torch.stack([even_pos_embed, odd_pos_embed], dim=2)  #(3)\n",
    "        #print(f\"stacked\\t\\t: {stacked.shape}\")\n",
    "\n",
    "        pos_embed = torch.flatten(stacked, start_dim=1, end_dim=2)  #(4)\n",
    "        #print(f\"pos_embed\\t: {pos_embed.shape}\")\n",
    "        \n",
    "        return pos_embed\n",
    "\n",
    "# mine\n",
    "class SinusoidPositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        max_seq_len=config.MAX_TEXT_SEQUENCE_LENGTH,\n",
    "        emb_dim=config.TEXT_EMBEDDING_DIM\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # create the positional encoding tensor of shape\n",
    "        # maximum sequence length (L) by embedding dimension (D)\n",
    "        pe = torch.zeros(max_seq_len, emb_dim, dtype=torch.float)\n",
    "\n",
    "        # positions indexes: [0, 1, 2, ..., max_seq_len-1], with shape (L, 1)\n",
    "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
    "        # frequency division terms with shape (D/2,) or (1, D/2)\n",
    "        # use log for numerical stability: a**b = exp(b * log(a))\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, emb_dim, 2) * (-math.log(10000) / emb_dim)\n",
    "        )\n",
    "\n",
    "        # even positional encodings use sine, odd cosine\n",
    "        # matrix-slice shape: (L, D/2), resulting matrix shape: (L, D)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # Buffers are for tensors that are not learnable parameters (no gradients) but are still part of the model's state\n",
    "        self.register_buffer('pe', pe.unsqueeze(0), persistent=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # For regular inference, we don't need to pad the embeddings to max_seq_len anymore\n",
    "        # Retrieve embeddings up to sequence length (S). output shape (1, S, C)\n",
    "        return self.pe[:, :x.shape[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d85b717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sinusoidal embedding\t: torch.Size([10, 768])\n",
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  8.2843e-01,  ...,  1.0000e+00,\n",
      "          1.0243e-04,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  9.2799e-01,  ...,  1.0000e+00,\n",
      "          2.0486e-04,  1.0000e+00],\n",
      "        ...,\n",
      "        [ 6.5699e-01,  7.5390e-01,  5.2347e-01,  ...,  1.0000e+00,\n",
      "          7.1699e-04,  1.0000e+00],\n",
      "        [ 9.8936e-01, -1.4550e-01,  9.9905e-01,  ...,  1.0000e+00,\n",
      "          8.1942e-04,  1.0000e+00],\n",
      "        [ 4.1212e-01, -9.1113e-01,  5.9565e-01,  ...,  1.0000e+00,\n",
      "          9.2185e-04,  1.0000e+00]])\n",
      "sinusoidal embedding\t: torch.Size([1, 10, 768])\n",
      "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
      "           0.0000e+00,  1.0000e+00],\n",
      "         [ 8.4147e-01,  5.4030e-01,  8.2843e-01,  ...,  1.0000e+00,\n",
      "           1.0243e-04,  1.0000e+00],\n",
      "         [ 9.0930e-01, -4.1615e-01,  9.2799e-01,  ...,  1.0000e+00,\n",
      "           2.0486e-04,  1.0000e+00],\n",
      "         ...,\n",
      "         [ 6.5699e-01,  7.5390e-01,  5.2347e-01,  ...,  1.0000e+00,\n",
      "           7.1699e-04,  1.0000e+00],\n",
      "         [ 9.8936e-01, -1.4550e-01,  9.9905e-01,  ...,  1.0000e+00,\n",
      "           8.1942e-04,  1.0000e+00],\n",
      "         [ 4.1212e-01, -9.1113e-01,  5.9565e-01,  ...,  1.0000e+00,\n",
      "           9.2185e-04,  1.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10\n",
    "sinusoidal_embedding = SinusoidalEmbedding()\n",
    "pos_embed_1 = sinusoidal_embedding(seq_len)\n",
    "print(f'sinusoidal embedding\\t: {pos_embed_1.size()}')\n",
    "print(pos_embed_1)\n",
    "\n",
    "sinusoidal_embedding = SinusoidPositionalEncoding()\n",
    "pos_embed_2 = sinusoidal_embedding(torch.zeros(1, seq_len, config.TEXT_EMBEDDING_DIM))\n",
    "print(f'sinusoidal embedding\\t: {pos_embed_2.size()}')\n",
    "print(pos_embed_2)\n",
    "\n",
    "assert torch.allclose(pos_embed_1, pos_embed_2.squeeze(0), atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d1a2462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPTR paper\n",
    "class DecoderBlock(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.self_attention = torch.nn.MultiheadAttention(embed_dim=config.EMBEDDING_DIM, \n",
    "                                                    num_heads=config.DECODER_NUM_HEADS, \n",
    "                                                    batch_first=True, \n",
    "                                                    dropout=config.DECODER_DROPOUT_PROB)\n",
    "        self.layer_norm_0 = torch.nn.LayerNorm(config.EMBEDDING_DIM)\n",
    "        self.cross_attention = torch.nn.MultiheadAttention(embed_dim=config.EMBEDDING_DIM, \n",
    "                                                     num_heads=config.DECODER_NUM_HEADS, \n",
    "                                                     batch_first=True, \n",
    "                                                     dropout=config.DECODER_DROPOUT_PROB)\n",
    "        self.layer_norm_1 = torch.nn.LayerNorm(config.EMBEDDING_DIM)       \n",
    "        self.ffn = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=config.EMBEDDING_DIM, out_features=config.DECODER_HIDDEN_DIM),\n",
    "            torch.nn.GELU(), \n",
    "            torch.nn.Dropout(p=config.DECODER_DROPOUT_PROB), \n",
    "            torch.nn.Linear(in_features=config.DECODER_HIDDEN_DIM, out_features=config.EMBEDDING_DIM),\n",
    "        )\n",
    "        self.layer_norm_2 = torch.nn.LayerNorm(config.EMBEDDING_DIM)\n",
    "        \n",
    "    def forward(self, features, captions, attn_mask):\n",
    "        print(f\"attn_mask\\t\\t: {attn_mask.shape}\")\n",
    "        residual = captions\n",
    "        print(f\"captions & residual\\t: {captions.shape}\")\n",
    "        \n",
    "        captions, self_attn_weights = self.self_attention(query=captions, \n",
    "                                                          key=captions, \n",
    "                                                          value=captions, \n",
    "                                                          attn_mask=attn_mask)\n",
    "        print(f\"after self attention\\t: {captions.shape}\")\n",
    "        print(f\"self attn weights\\t: {self_attn_weights.shape}\")\n",
    "        \n",
    "        captions = self.layer_norm_0(captions + residual)\n",
    "        print(f\"after norm\\t\\t: {captions.shape}\")\n",
    "        \n",
    "        print(f\"\\nfeatures\\t\\t: {features.shape}\")\n",
    "        residual = captions\n",
    "        print(f\"captions & residual\\t: {captions.shape}\")\n",
    "        \n",
    "        captions, cross_attn_weights = self.cross_attention(query=captions, \n",
    "                                                            key=features, \n",
    "                                                            value=features)\n",
    "        print(f\"after cross attention\\t: {captions.shape}\")\n",
    "        print(f\"cross attn weights\\t: {cross_attn_weights.shape}\")\n",
    "        \n",
    "        captions = self.layer_norm_1(captions + residual)\n",
    "        print(f\"after norm\\t\\t: {captions.shape}\")\n",
    "        \n",
    "        residual = captions\n",
    "        print(f\"\\ncaptions & residual\\t: {captions.shape}\")\n",
    "        \n",
    "        captions = self.ffn(captions)  \n",
    "        print(f\"after ffn\\t\\t: {captions.shape}\")\n",
    "        \n",
    "        captions = self.layer_norm_2(captions + residual)\n",
    "        print(f\"after norm\\t\\t: {captions.shape}\")\n",
    "        \n",
    "        return captions\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size,\n",
    "                                      embedding_dim=config.EMBEDDING_DIM)\n",
    "        self.sinusoidal_embedding = SinusoidalEmbedding()\n",
    "        self.decoder_blocks = torch.nn.ModuleList(DecoderBlock() for _ in range(config.DECODER_NUM_BLOCKS))\n",
    "        self.linear = torch.nn.Linear(in_features=config.EMBEDDING_DIM, \n",
    "                                out_features=vocab_size)\n",
    "        \n",
    "    def forward(self, features, captions, attn_mask):  #(1)\n",
    "        print(f\"features\\t\\t: {features.shape}\")\n",
    "        print(f\"captions\\t\\t: {captions.shape}\")\n",
    "        \n",
    "        captions = self.embedding(captions)  #(2)\n",
    "        print(f\"after embedding\\t\\t: {captions.shape}\")\n",
    "        \n",
    "        captions = captions + self.sinusoidal_embedding(captions.shape[1]).to(captions.device)  #(3)\n",
    "        print(f\"after sin embed\\t\\t: {captions.shape}\")\n",
    "        \n",
    "        for i, decoder_block in enumerate(self.decoder_blocks):\n",
    "            captions = decoder_block(features, captions, attn_mask)  #(4)\n",
    "            print(f\"after decoder block #{i}\\t: {captions.shape}\")\n",
    "        \n",
    "        captions = self.linear(captions)  #(5)\n",
    "        print(f\"after linear\\t\\t: {captions.shape}\")\n",
    "        \n",
    "        return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94dfad0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1837, -0.7576, -2.7767,  ...,  0.2307,  0.5473,  0.7948],\n",
       "         [-0.5727,  0.4069, -2.2995,  ..., -1.2037,  0.0416,  1.7350],\n",
       "         [-1.1595, -0.3293,  0.0287,  ...,  0.9144, -0.4494, -1.6718],\n",
       "         ...,\n",
       "         [-0.4221,  1.2612, -1.1061,  ..., -0.1490,  0.4487, -2.0981],\n",
       "         [ 1.2520,  1.6494,  1.3075,  ...,  2.0961, -0.0689,  0.5034],\n",
       "         [ 0.9881, -0.9955,  1.2436,  ..., -0.3074, -2.1582,  0.7660]],\n",
       "\n",
       "        [[-1.0846, -0.1489, -1.2281,  ...,  0.1600, -0.9643, -0.0949],\n",
       "         [ 0.1687, -0.7035, -0.6381,  ..., -0.2588,  0.7814, -2.3095],\n",
       "         [-1.4492,  0.5908,  1.9926,  ...,  0.6617, -0.3175, -1.2848],\n",
       "         ...,\n",
       "         [-0.6023, -0.0891, -0.0363,  ..., -1.0226, -0.2452, -0.6040],\n",
       "         [ 1.8762,  0.4930,  1.0663,  ..., -0.8836, -0.5276, -0.3208],\n",
       "         [-0.1763,  1.3944, -0.2470,  ...,  0.0067,  0.9317, -1.7565]],\n",
       "\n",
       "        [[-0.6069,  0.0825,  0.0655,  ...,  0.3664, -0.7940, -0.1469],\n",
       "         [ 0.7718, -1.9250,  1.5158,  ...,  0.1997,  1.1182,  1.7113],\n",
       "         [ 0.0575, -0.8896,  0.8501,  ...,  0.7352, -0.1096, -0.9881],\n",
       "         ...,\n",
       "         [-1.9462,  0.2934,  0.6600,  ..., -2.9618,  0.1964, -0.4883],\n",
       "         [-0.9852,  0.0950, -1.1481,  ...,  1.1303,  0.6026, -0.3592],\n",
       "         [-0.8719,  0.1398, -1.4554,  ..., -1.5236,  1.2116,  0.2702]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1893, -1.7663, -0.6174,  ...,  1.5218,  0.0737,  0.0766],\n",
       "         [-1.3321, -1.3509, -0.4398,  ..., -0.9178, -0.5694,  2.5495],\n",
       "         [-0.4938,  0.0493,  0.7729,  ..., -0.4401, -0.1855, -1.4145],\n",
       "         ...,\n",
       "         [-1.5761, -0.9905, -0.3670,  ...,  1.7587, -0.1518, -0.2636],\n",
       "         [ 1.0877, -0.3499, -0.7753,  ...,  1.4113,  2.1723, -0.7707],\n",
       "         [-1.8032,  0.0771, -1.7302,  ..., -0.3542, -0.6697, -0.5063]],\n",
       "\n",
       "        [[-0.5326,  0.7567,  0.1164,  ...,  1.7098, -0.2677,  1.0264],\n",
       "         [-0.4965,  0.9143, -0.6629,  ..., -1.8330, -0.4233,  0.3256],\n",
       "         [-2.5435,  1.2182,  0.0454,  ...,  1.1545,  1.5292, -0.8303],\n",
       "         ...,\n",
       "         [ 0.1623, -0.4662,  0.9102,  ...,  2.2963, -0.1444, -1.6042],\n",
       "         [ 0.8060,  0.9079, -1.4248,  ..., -2.5989, -0.7585, -1.2617],\n",
       "         [-1.3084,  0.4752, -0.7260,  ...,  0.0368, -0.7272,  0.9876]],\n",
       "\n",
       "        [[ 1.4021, -1.6227,  0.4842,  ..., -0.5285,  1.3191,  0.2738],\n",
       "         [-1.1559,  0.2077, -0.3021,  ..., -1.3715,  0.3024, -0.5245],\n",
       "         [-0.0906, -0.8974, -0.2216,  ..., -1.2531,  0.0142, -0.2892],\n",
       "         ...,\n",
       "         [ 0.1291,  0.6961, -1.9233,  ..., -0.4941,  0.0112, -0.1115],\n",
       "         [ 0.1291,  0.0379,  0.9786,  ...,  0.8455, -1.5167,  1.2702],\n",
       "         [ 0.2520,  0.5904,  1.0503,  ..., -0.3928, -0.1770, -1.4809]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_block = DecoderBlock()\n",
    "seq_length = 10\n",
    "vocab_size = 100\n",
    "\n",
    "features = torch.randn(config.BATCH_SIZE_TRAIN, config.NUM_PATCHES, config.EMBEDDING_DIM)\n",
    "captions = torch.randn(config.BATCH_SIZE_TRAIN, seq_length, config.EMBEDDING_DIM)\n",
    "look_ahead_mask = create_mask(seq_length=seq_length)\n",
    "\n",
    "decoder_block(features, captions, look_ahead_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b9cc9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions\t\t: torch.Size([16, 10])\n",
      "after embedding\t\t: torch.Size([16, 10, 768])\n",
      "after sin embed\t\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block #0\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block #1\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block #2\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block #3\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block #4\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block #5\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block #6\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block #7\t: torch.Size([16, 10, 768])\n",
      "after linear\t\t: torch.Size([16, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_size=vocab_size)\n",
    "\n",
    "features2 = torch.randn(config.BATCH_SIZE_TRAIN, config.NUM_PATCHES, config.EMBEDDING_DIM)\n",
    "captions2 = torch.randint(0, vocab_size, (config.BATCH_SIZE_TRAIN, seq_length))  #(1)\n",
    "\n",
    "logits = decoder(features2, captions2, look_ahead_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a46ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine\n",
    "class LearnableWordEmbedding(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, padding_idx):\n",
    "        super(LearnableWordEmbedding, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=emb_dim, padding_idx=padding_idx)\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        assert input_ids.dtype == torch.long, f\"Input tensor must have dtype torch.long, got {input_ids.dtype}\"\n",
    "        embeddings = self.embedding(input_ids)\n",
    "        return embeddings\n",
    "\n",
    "class DecoderBlock(torch.nn.Module):\n",
    "    def __init__(self, embed_dim=config.EMBEDDING_DIM, num_heads=config.DECODER_NUM_HEADS, hidden_dim=config.DECODER_HIDDEN_DIM, dropout_prob=config.DECODER_DROPOUT_PROB, bias=config.USE_BIAS, sublayer_dropout=config.SUBLAYER_DROPOUT, verbose=False):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.MMHSA = torch.nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, batch_first=True, dropout=dropout_prob, bias=bias)\n",
    "        self.layer_norm_1 = torch.nn.LayerNorm(embed_dim)\n",
    "        # the bridge between the encoder and the decoder, K and V come from encoder, Q is derived from the previous decoder sublayer\n",
    "        self.MHCA = torch.nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, batch_first=True, dropout=dropout_prob / 2, bias=bias)\n",
    "        self.layer_norm_2 = torch.nn.LayerNorm(embed_dim)\n",
    "        self.FFN = torch.nn.Sequential(\n",
    "            torch.nn.Linear(embed_dim, hidden_dim, bias=bias),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(p=dropout_prob),\n",
    "            torch.nn.Linear(hidden_dim, embed_dim, bias=bias)\n",
    "        )\n",
    "        self.layer_norm_3 = torch.nn.LayerNorm(embed_dim)\n",
    "        if sublayer_dropout:\n",
    "            self.sublayer_dropout = torch.nn.Dropout(p=dropout_prob)\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'DecoderBlock initialized with embed_dim={embed_dim}, num_heads={num_heads}, hidden_dim={hidden_dim}, dropout_prob={dropout_prob}, bias={bias}')\n",
    "\n",
    "    def forward(self, x, k, v, attn_mask, pad_mask):\n",
    "        print(f\"attn_mask\\t\\t: {attn_mask.shape}\")\n",
    "\n",
    "        if x.ndim != 3:\n",
    "            raise ValueError(f'Input tensor x must have 3 dimensions (batch_size, seq_length, embed_dim), but got {x.ndim} dimensions.')\n",
    "        \n",
    "        print(f\"captions & residual\\t: {x.shape}\")\n",
    "\n",
    "        attn_output, mmhsa_w = self.MMHSA(query=x, key=x, value=x, attn_mask=attn_mask, key_padding_mask=pad_mask)\n",
    "        # print('Masked Multi-Head Self-Attention weights shape:', mmhsa_w.shape)\n",
    "        \n",
    "        print(f\"after self attention\\t: {attn_output.shape}\")\n",
    "        print(f\"self attn weights\\t: {mmhsa_w.shape}\")\n",
    "        \n",
    "        if hasattr(self, 'sublayer_dropout'):\n",
    "            # apply dropout before layer normalization for each sublayer\n",
    "            attn_output = self.sublayer_dropout(attn_output)\n",
    "            print(f'after sublayer dropout\\t: {attn_output.shape}')\n",
    "            \n",
    "        x = self.layer_norm_1(x + attn_output) # TODO: debug cross attention, and text vs img embeddings as inputs\n",
    "        print(f\"after norm\\t\\t: {x.shape}\")\n",
    "\n",
    "        print(f\"\\nfeatures\\t\\t: {k.shape}\")\n",
    "        assert k is v  # just to indicate that k and v are from the encoder output\n",
    "        print(f\"captions & residual\\t: {x.shape}\")\n",
    "        \n",
    "        attn_output, mhca_w = self.MHCA(query=x, key=k, value=v)\n",
    "        # print('Cross Attention weights shape:', mhca_w.shape)\n",
    "        \n",
    "        print(f\"after cross attention\\t: {attn_output.shape}\")\n",
    "        print(f\"cross attn weights\\t: {mhca_w.shape}\")\n",
    "        \n",
    "        if hasattr(self, 'sublayer_dropout'):\n",
    "            # apply dropout before layer normalization for each sublayer\n",
    "            attn_output = self.sublayer_dropout(attn_output)\n",
    "            print(f'after sublayer dropout\\t: {attn_output.shape}')\n",
    "        \n",
    "        x = self.layer_norm_2(x + attn_output)\n",
    "        print(f\"after norm\\t\\t: {x.shape}\")\n",
    "        \n",
    "        ff_output = self.FFN(x)\n",
    "        print(f\"after ffn\\t\\t: {captions.shape}\")\n",
    "        \n",
    "        x = self.layer_norm_3(x + ff_output)\n",
    "        print(f\"after norm\\t\\t: {x.shape}\")\n",
    "        \n",
    "        # print(f\"Cross-attn weights mean: {mhca_w.mean()}, std: {mhca_w.std()}\")\n",
    "        return x\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, num_blocks=config.DECODER_NUM_BLOCKS, embed_dim=config.EMBEDDING_DIM, num_heads=config.DECODER_NUM_HEADS, hidden_dim=config.DECODER_HIDDEN_DIM, dropout_prob=config.DECODER_DROPOUT_PROB, bias=config.USE_BIAS, sublayer_dropout=config.SUBLAYER_DROPOUT, verbose=False):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_blocks = torch.nn.ModuleList()\n",
    "        for _ in range(num_blocks):\n",
    "            self.decoder_blocks.append(DecoderBlock(embed_dim=embed_dim, num_heads=num_heads, hidden_dim=hidden_dim, dropout_prob=dropout_prob, bias=bias, sublayer_dropout=sublayer_dropout, verbose=verbose))\n",
    "\n",
    "    def forward(self, x, enc_output, attn_mask, pad_mask):\n",
    "        for block in self.decoder_blocks:\n",
    "            x = block.forward(x, k=enc_output, v=enc_output, attn_mask=attn_mask, pad_mask=pad_mask)\n",
    "            print(f\"after decoder block\\t: {x.shape}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2411b201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.3416e-01,  3.3404e-01, -2.1292e+00,  ...,  4.2771e-01,\n",
       "           8.7622e-01,  4.1506e-01],\n",
       "         [-5.1127e-01,  4.9171e-01, -1.9297e+00,  ..., -1.3645e+00,\n",
       "          -5.8908e-01,  1.2489e+00],\n",
       "         [-8.3136e-01, -2.1311e-01,  1.7480e-01,  ...,  9.3618e-01,\n",
       "          -6.1393e-01, -1.5810e+00],\n",
       "         ...,\n",
       "         [-2.1087e-01,  1.0485e+00, -9.2834e-01,  ...,  2.2675e-01,\n",
       "           3.2850e-01, -2.7942e+00],\n",
       "         [ 9.6728e-01,  1.8492e+00,  1.1786e+00,  ...,  2.6246e+00,\n",
       "           8.8281e-02,  2.0738e-01],\n",
       "         [ 7.1426e-01, -7.3996e-01,  1.4532e+00,  ..., -8.6416e-01,\n",
       "          -2.5485e+00,  4.4710e-01]],\n",
       "\n",
       "        [[-3.8362e-01, -6.7436e-01, -7.2990e-01,  ...,  1.2693e-01,\n",
       "          -5.7018e-01,  9.8554e-01],\n",
       "         [ 3.4430e-01, -5.1261e-01, -5.3866e-01,  ..., -7.2104e-01,\n",
       "           5.9544e-01, -1.3046e+00],\n",
       "         [-1.3354e+00,  5.0809e-01,  1.8878e+00,  ...,  9.6029e-04,\n",
       "          -2.8837e-01, -7.3275e-01],\n",
       "         ...,\n",
       "         [-1.2037e+00,  2.3279e-01,  1.1375e-01,  ..., -1.5551e+00,\n",
       "           1.5101e-01,  8.2772e-01],\n",
       "         [ 1.4808e+00,  1.1145e-01,  1.2686e+00,  ..., -1.4024e+00,\n",
       "          -4.6728e-01,  3.2870e-01],\n",
       "         [-3.5721e-01,  9.8684e-01,  1.6326e-01,  ..., -8.7192e-02,\n",
       "           9.6786e-01, -1.2472e+00]],\n",
       "\n",
       "        [[-1.1606e+00, -4.4643e-02,  1.5719e+00,  ..., -3.8497e-01,\n",
       "          -3.5862e-01,  6.8621e-01],\n",
       "         [ 7.0863e-01, -1.9473e+00,  1.8548e+00,  ..., -8.2149e-01,\n",
       "           1.9242e+00,  2.5734e+00],\n",
       "         [-6.9312e-01, -2.1476e-01,  1.0954e+00,  ...,  1.0008e-01,\n",
       "           8.7453e-01,  9.3720e-02],\n",
       "         ...,\n",
       "         [-1.9799e+00,  5.0421e-01,  1.0134e+00,  ..., -2.9137e+00,\n",
       "           2.5720e-01, -3.4195e-01],\n",
       "         [-1.0905e+00,  7.8048e-02, -1.3305e+00,  ...,  1.2153e+00,\n",
       "           1.1147e+00, -2.9409e-01],\n",
       "         [-9.2988e-01,  3.9018e-01, -1.2605e+00,  ..., -9.7247e-01,\n",
       "           1.7296e+00,  2.6238e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3.5056e-01, -1.5645e+00,  3.1318e-03,  ...,  1.2695e+00,\n",
       "          -1.9462e-03, -2.7952e-01],\n",
       "         [-1.2096e+00, -1.4857e+00, -1.2090e-01,  ..., -7.4742e-01,\n",
       "          -2.8258e-01,  1.8702e+00],\n",
       "         [-2.1325e-01, -1.2176e-01,  9.7545e-01,  ..., -1.2871e+00,\n",
       "           4.3091e-01, -1.3490e+00],\n",
       "         ...,\n",
       "         [-1.5537e+00, -1.1929e+00,  5.5273e-01,  ...,  1.1626e+00,\n",
       "          -3.7414e-01, -5.2226e-01],\n",
       "         [ 1.3845e+00, -4.3385e-01, -6.3198e-01,  ...,  1.3241e+00,\n",
       "           1.5735e+00, -3.9118e-01],\n",
       "         [-1.5940e+00,  8.2514e-02, -1.3501e+00,  ..., -1.6663e-01,\n",
       "          -4.8017e-01, -4.6976e-01]],\n",
       "\n",
       "        [[-4.7850e-01,  5.7436e-01,  6.4238e-02,  ...,  1.8274e+00,\n",
       "           3.5531e-01,  2.7075e-01],\n",
       "         [-6.5042e-01,  3.4644e-01, -3.0519e-01,  ..., -1.3330e+00,\n",
       "          -1.3875e-01,  2.9489e-01],\n",
       "         [-1.5112e+00,  1.4209e+00,  9.0606e-01,  ...,  1.3779e+00,\n",
       "           2.1641e+00, -1.3469e+00],\n",
       "         ...,\n",
       "         [ 1.4043e-01,  2.0220e-01,  6.6513e-01,  ...,  2.0976e+00,\n",
       "           1.0145e-01, -1.3829e+00],\n",
       "         [ 5.8869e-01,  1.2263e+00, -1.0538e+00,  ..., -2.8468e+00,\n",
       "          -6.1293e-01, -1.1405e+00],\n",
       "         [-7.8241e-01,  1.1266e+00, -6.3816e-01,  ..., -3.0810e-01,\n",
       "          -3.8786e-01,  1.4138e+00]],\n",
       "\n",
       "        [[ 1.8724e+00, -1.4598e+00,  8.5297e-01,  ..., -3.3894e-01,\n",
       "           6.7789e-01,  6.7717e-01],\n",
       "         [-3.5350e-02,  8.1773e-01, -2.9745e-01,  ..., -1.1139e+00,\n",
       "           5.3864e-01, -4.8947e-01],\n",
       "         [ 4.9664e-01, -3.1867e-01, -3.1122e-01,  ..., -5.6786e-01,\n",
       "          -3.0093e-02,  1.2422e-02],\n",
       "         ...,\n",
       "         [ 5.0106e-01,  1.3952e+00, -1.6826e+00,  ..., -6.4498e-01,\n",
       "          -1.5432e-01,  6.3302e-01],\n",
       "         [ 2.9600e-01,  8.6644e-02,  7.6098e-01,  ...,  2.9337e-01,\n",
       "          -7.9951e-01,  1.5356e+00],\n",
       "         [ 2.3003e-01,  8.5354e-01,  4.9790e-01,  ..., -9.7548e-01,\n",
       "           1.4303e-01, -9.0557e-01]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_block = DecoderBlock()\n",
    "seq_length = 10\n",
    "\n",
    "look_ahead_mask = get_causal_mask(seq_length, device='cpu')\n",
    "\n",
    "decoder_block(x=captions, k=features, v=features, attn_mask=look_ahead_mask, pad_mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "651ee4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions\t\t: torch.Size([16, 10])\n",
      "after embedding\t\t: torch.Size([16, 10, 768])\n",
      "after sin embed\t\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block\t: torch.Size([16, 10, 768])\n",
      "attn_mask\t\t: torch.Size([10, 10])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after self attention\t: torch.Size([16, 10, 768])\n",
      "self attn weights\t: torch.Size([16, 10, 10])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "\n",
      "features\t\t: torch.Size([16, 196, 768])\n",
      "captions & residual\t: torch.Size([16, 10, 768])\n",
      "after cross attention\t: torch.Size([16, 10, 768])\n",
      "cross attn weights\t: torch.Size([16, 10, 196])\n",
      "after sublayer dropout\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after ffn\t\t: torch.Size([16, 10, 768])\n",
      "after norm\t\t: torch.Size([16, 10, 768])\n",
      "after decoder block\t: torch.Size([16, 10, 768])\n",
      "after decoder\t\t: torch.Size([16, 10, 768])\n",
      "after linear\t\t: torch.Size([16, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder()\n",
    "seq_length = 10\n",
    "word_embedding = LearnableWordEmbedding(vocab_size=vocab_size, emb_dim=config.EMBEDDING_DIM, padding_idx=0)\n",
    "text_pos_embedding = SinusoidPositionalEncoding(max_seq_len=seq_length, emb_dim=config.EMBEDDING_DIM)\n",
    "scaling = float(math.sqrt(config.EMBEDDING_DIM))\n",
    "text_layernorm = torch.nn.LayerNorm(config.EMBEDDING_DIM)\n",
    "linear = torch.nn.Linear(in_features=config.EMBEDDING_DIM, out_features=vocab_size, bias=False)\n",
    "\n",
    "if captions2.ndim < 2:\n",
    "    captions2 = captions2.unsqueeze(0)\n",
    "    \n",
    "print(f\"features\\t\\t: {features2.shape}\")\n",
    "print(f\"captions\\t\\t: {captions2.shape}\")\n",
    "embeddings = word_embedding(captions2) * scaling # (B, L) -> (B, L, D)\n",
    "print(f\"after embedding\\t\\t: {embeddings.shape}\")\n",
    "emb_sum = text_layernorm(embeddings + text_pos_embedding(embeddings))\n",
    "print(f\"after sin embed\\t\\t: {emb_sum.shape}\")\n",
    "look_ahead_mask = get_causal_mask(seq_length, device='cpu')\n",
    "emb_sum = decoder.forward(x=emb_sum, enc_output=features2, attn_mask=look_ahead_mask, pad_mask=None)\n",
    "print(f\"after decoder\\t\\t: {emb_sum.shape}\")\n",
    "logits2 = linear(emb_sum)\n",
    "print(f\"after linear\\t\\t: {logits2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe5decc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4130, -0.4306, -0.0816,  ...,  0.1188,  0.5913, -0.2970],\n",
       "         [ 0.3047,  0.0847, -0.3114,  ..., -0.1341,  0.3454,  0.1895],\n",
       "         [ 0.5813,  0.1061,  0.3691,  ..., -0.4163,  0.5673,  0.2931],\n",
       "         ...,\n",
       "         [ 0.1183, -0.2991, -0.3510,  ..., -0.4637,  0.7381, -0.0739],\n",
       "         [-0.1190, -0.0209,  0.0964,  ..., -0.5067, -0.3995,  0.1112],\n",
       "         [-0.1231, -0.1341, -0.6384,  ..., -0.6273,  0.6650, -0.0636]],\n",
       "\n",
       "        [[ 0.4517, -0.4660,  0.2228,  ...,  0.2315,  0.3761,  0.2205],\n",
       "         [ 0.4460,  0.3141, -0.1004,  ..., -0.0131,  0.7769, -0.2664],\n",
       "         [ 1.3634,  0.5658,  0.3277,  ..., -0.2082,  1.1667, -0.0242],\n",
       "         ...,\n",
       "         [ 0.0736,  0.2406,  0.5238,  ..., -0.0521,  0.7081,  0.1330],\n",
       "         [ 0.3931,  0.2186,  0.2434,  ...,  0.1645,  0.4580, -0.1352],\n",
       "         [-0.4153,  0.4832,  0.4907,  ..., -0.0234, -0.3881, -0.7151]],\n",
       "\n",
       "        [[-0.1996,  0.3906,  0.6869,  ..., -0.7563,  0.8874,  0.6080],\n",
       "         [-0.2705,  0.6698,  0.8896,  ..., -0.8232,  0.7240,  0.6529],\n",
       "         [ 0.3747, -0.0982,  0.9530,  ..., -0.3736,  0.7527,  0.9936],\n",
       "         ...,\n",
       "         [ 0.3818, -0.4585,  0.6349,  ..., -0.4053,  0.1580,  0.2717],\n",
       "         [ 0.1647,  0.2842,  0.4865,  ..., -0.1162,  0.7395,  1.0381],\n",
       "         [ 0.1556,  0.1929,  0.9810,  ...,  0.0302,  0.4231,  0.0643]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0266,  0.4421,  0.4838,  ..., -0.2628,  0.0752,  0.8167],\n",
       "         [ 0.1603,  0.1112,  0.2883,  ..., -0.5903,  0.3765,  0.5317],\n",
       "         [ 0.2299, -0.0021,  0.7515,  ..., -0.1463, -0.4031,  0.4895],\n",
       "         ...,\n",
       "         [ 0.6067, -0.4302,  0.1261,  ...,  0.4624,  0.3071,  0.2266],\n",
       "         [ 0.3513, -0.6953, -0.2847,  ...,  0.1458, -0.1990,  0.6738],\n",
       "         [ 0.1881, -0.0176,  0.1094,  ...,  0.0536,  0.0388, -0.3366]],\n",
       "\n",
       "        [[ 0.0648, -0.0482,  0.5338,  ...,  0.4535,  0.3956,  0.6816],\n",
       "         [ 0.1423, -0.0637,  0.5695,  ..., -0.1833,  0.2656, -0.0768],\n",
       "         [ 0.3417, -0.2042,  0.4376,  ..., -0.5510,  0.7441,  1.4001],\n",
       "         ...,\n",
       "         [-0.0976, -0.5158,  1.4190,  ...,  0.0547,  0.6380,  0.2364],\n",
       "         [ 0.2904, -0.9794, -0.1278,  ...,  0.0898,  0.0885,  1.2801],\n",
       "         [ 0.6112, -0.3441,  0.7990,  ..., -0.2993,  0.9493,  0.1364]],\n",
       "\n",
       "        [[ 0.8461,  0.8926,  0.4682,  ..., -0.1460,  0.2927,  0.3286],\n",
       "         [ 0.5609,  0.1513, -0.2246,  ..., -0.8033,  0.1554, -0.0193],\n",
       "         [ 0.2892,  0.1187,  0.3870,  ..., -0.6007,  0.5651,  0.4726],\n",
       "         ...,\n",
       "         [ 0.5904, -0.3537,  0.9837,  ..., -0.1387, -0.3979,  0.8964],\n",
       "         [ 0.0243, -0.3548,  0.6624,  ..., -0.5812,  0.6716,  0.4841],\n",
       "         [ 0.6327,  0.0442,  0.2355,  ..., -0.1721,  0.3045,  0.7598]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a47e8206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.9101e-01,  8.6618e-01,  1.3693e+00,  ...,  9.6197e-01,\n",
       "          -4.5276e-01,  5.9621e-01],\n",
       "         [ 2.9232e-01,  2.4911e-01,  2.2399e-01,  ...,  8.0683e-01,\n",
       "           2.6057e-01,  1.3982e-01],\n",
       "         [-7.9646e-02, -3.3085e-01, -1.6185e-01,  ..., -1.0459e-02,\n",
       "          -4.5896e-01,  3.7201e-01],\n",
       "         ...,\n",
       "         [-3.8962e-01,  5.1925e-01,  5.9397e-01,  ..., -4.2894e-01,\n",
       "          -1.0360e-01,  6.4018e-01],\n",
       "         [-3.5843e-01,  1.0844e-01,  2.2958e-01,  ...,  1.4756e-01,\n",
       "          -4.7098e-01,  1.3878e+00],\n",
       "         [-1.7488e-01, -3.5876e-01,  1.6078e+00,  ..., -8.3904e-01,\n",
       "          -2.9858e-01,  5.8744e-01]],\n",
       "\n",
       "        [[-7.4357e-01,  1.3332e+00, -6.0248e-01,  ...,  2.9850e-01,\n",
       "           2.7847e-02, -1.5093e+00],\n",
       "         [-4.6255e-01,  1.2842e+00, -2.8054e-01,  ..., -4.5028e-01,\n",
       "           4.8370e-01,  2.9548e-01],\n",
       "         [-6.4049e-02,  9.6061e-02, -4.8833e-01,  ...,  3.0619e-01,\n",
       "          -2.8517e-01, -1.9401e-01],\n",
       "         ...,\n",
       "         [-8.6611e-02,  2.4275e-01, -1.0775e-01,  ..., -8.5074e-02,\n",
       "          -1.2293e-01,  7.4609e-02],\n",
       "         [-1.2246e-01,  8.9465e-03, -8.9675e-05,  ..., -1.0113e-01,\n",
       "           6.2186e-03, -3.6321e-01],\n",
       "         [-5.3102e-02, -3.0597e-01, -9.2916e-01,  ..., -1.0519e+00,\n",
       "          -1.2636e+00, -2.2975e-01]],\n",
       "\n",
       "        [[-3.4505e-01, -1.6163e-01, -2.3959e-01,  ...,  8.0508e-01,\n",
       "           2.3557e-01, -6.8446e-01],\n",
       "         [-6.4417e-01, -1.9941e-01,  4.4232e-01,  ...,  6.4345e-01,\n",
       "          -5.2685e-01, -3.3060e-01],\n",
       "         [ 1.1790e+00,  1.3178e-01,  1.8250e-01,  ..., -1.7835e-01,\n",
       "          -1.3824e-01, -4.6793e-01],\n",
       "         ...,\n",
       "         [-4.9229e-01, -4.2135e-02, -7.2642e-01,  ..., -5.6483e-01,\n",
       "           6.7260e-01, -3.0380e-01],\n",
       "         [-2.0489e-01, -7.7982e-01,  3.0556e-01,  ..., -4.8018e-03,\n",
       "          -2.2246e-01,  6.1812e-01],\n",
       "         [ 4.0085e-01,  3.1499e-01, -2.0560e-01,  ..., -4.8975e-01,\n",
       "           8.3288e-02,  2.4565e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 4.7421e-01,  2.6567e-01,  4.8869e-01,  ...,  3.7416e-01,\n",
       "           4.5492e-04, -5.2774e-01],\n",
       "         [-1.1757e+00,  4.2432e-01,  4.5559e-01,  ...,  4.0707e-01,\n",
       "          -6.5324e-01, -4.6659e-01],\n",
       "         [-9.5398e-01, -3.4409e-01, -4.3621e-01,  ...,  7.2896e-01,\n",
       "          -4.2722e-01, -1.0088e+00],\n",
       "         ...,\n",
       "         [-2.9385e-01,  1.7283e-01,  2.4972e-01,  ...,  2.5562e-01,\n",
       "          -6.4807e-01, -5.1095e-01],\n",
       "         [ 1.8621e-01,  3.4081e-01,  8.6160e-02,  ..., -7.2634e-01,\n",
       "          -3.7039e-01, -6.1750e-02],\n",
       "         [-3.9518e-01,  3.6577e-01, -5.2643e-01,  ...,  2.6068e-01,\n",
       "          -1.2718e+00, -6.2434e-01]],\n",
       "\n",
       "        [[ 2.6886e-01,  1.5092e-01,  5.3501e-01,  ...,  2.8835e-01,\n",
       "          -8.1324e-01, -5.2969e-01],\n",
       "         [-1.6954e-01,  3.5267e-01, -1.4790e-01,  ...,  6.5910e-01,\n",
       "          -9.8221e-01, -8.5990e-01],\n",
       "         [-6.0723e-01,  4.4126e-01, -1.0215e-01,  ...,  3.0697e-01,\n",
       "           9.1946e-02, -9.5364e-01],\n",
       "         ...,\n",
       "         [ 1.5747e-02,  6.9555e-01, -5.1720e-01,  ..., -2.8617e-01,\n",
       "          -5.1049e-02,  1.4218e-01],\n",
       "         [ 3.1012e-01, -5.4016e-01, -3.2799e-01,  ...,  5.4352e-01,\n",
       "           2.3759e-01, -3.3066e-01],\n",
       "         [-3.5913e-01,  9.7766e-01,  6.4547e-01,  ..., -3.9482e-01,\n",
       "           1.0202e+00,  4.8458e-01]],\n",
       "\n",
       "        [[-3.6024e-01, -9.3282e-02,  4.8141e-01,  ..., -1.5691e-01,\n",
       "           3.8050e-01,  4.6980e-01],\n",
       "         [-2.9722e-01,  8.4099e-01,  5.7412e-01,  ..., -7.4852e-01,\n",
       "           3.1591e-01, -2.3310e-01],\n",
       "         [-1.6244e-02,  1.8025e-01,  7.0488e-01,  ..., -1.4708e+00,\n",
       "           7.6059e-01,  1.0199e+00],\n",
       "         ...,\n",
       "         [ 3.3101e-01, -3.7206e-01,  8.3126e-01,  ..., -1.3223e+00,\n",
       "           5.2432e-01,  3.9523e-01],\n",
       "         [ 9.3994e-02, -1.6648e-01, -8.9891e-01,  ..., -7.7841e-01,\n",
       "          -8.6647e-01, -1.0957e+00],\n",
       "         [ 5.5083e-01,  8.6586e-01,  6.8602e-01,  ...,  7.7558e-03,\n",
       "           8.9083e-01, -4.7381e-01]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "936bf19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits 1 - mean: 0.030457664281129837, std: 0.5799668431282043\n",
      "Logits 2 - mean: -0.03302059322595596, std: 0.5720139741897583\n"
     ]
    }
   ],
   "source": [
    "# calculate mean of logits and logits2\n",
    "mean_logits_1 = logits.mean().item()\n",
    "mean_logits_2 = logits2.mean().item()\n",
    "# calculate std of logits and logits2\n",
    "std_logits_1 = logits.std().item()\n",
    "std_logits_2 = logits2.std().item()\n",
    "print(f\"Logits 1 - mean: {mean_logits_1}, std: {std_logits_1}\")\n",
    "print(f\"Logits 2 - mean: {mean_logits_2}, std: {std_logits_2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
